{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from lightning import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics.functional import accuracy\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, text, seq_length=100):\n",
    "        self.chars = sorted(list(set(text)))\n",
    "        self.char_to_int = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.int_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        self.data_size, self.vocab_size = len(text), len(self.chars)\n",
    "        self.seq_length = seq_length\n",
    "        # self.embedding_dim = L.Embedding(num_embeddings=self.vocab_size, embedding_dim=256)\n",
    "\n",
    "        # Create training data\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        for i in range(0, self.data_size - seq_length, 1):\n",
    "            seq_in = text[i:i + seq_length]\n",
    "            seq_out = text[i + seq_length]\n",
    "            self.x.append([self.char_to_int[char] for char in seq_in])\n",
    "            self.y.append(self.char_to_int[seq_out])\n",
    "        self.x = np.array(self.x)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.x[index], dtype=torch.long), torch.tensor(self.y[index], dtype=torch.long)\n",
    "\n",
    "\n",
    "class TextGenerator(L.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, layers):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            num_layers=layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, logger=True,\n",
    "                 on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss, logger=True,\n",
    "                 on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, seq_length=100, train_split=0.7, valid_split=0.15):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    dataset = ShakespeareDataset(text, seq_length)\n",
    "    train_size = int(len(dataset) * train_split)\n",
    "    valid_size = int(len(dataset) * valid_split)\n",
    "    test_size = len(dataset) - train_size - valid_size\n",
    "    train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, valid_size, test_size])\n",
    "    return dataset, train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "\n",
    "# Load your datasets\n",
    "dataset, train_dataset, valid_dataset, test_dataset = load_data(\n",
    "    'input.txt', seq_length=100)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerator.load_from_checkpoint(\n",
    "    './lightning_logs/version_10/checkpoints/epoch=8-step=54900.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to behavour.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Uncleave Serempties\n",
      "To beder'd me well stay!\n",
      "\n",
      "SICINIUS:\n",
      "Pray you\n",
      "And yet false, then\n",
      "Edward within the east,\n",
      "As one riled words.\n",
      "Patience and crown\n",
      "To crase my moyself.\n",
      "My Lord Angelo, I\n",
      "Do with that one for\n",
      "offence, and theer heart\n",
      "Ay, there six fray goodly gentle?\n",
      "Ours: hed! O, for heaven\n",
      "wash the bild himself.\n",
      "Grean a facl down of no!\n",
      "Scape.\n",
      "You worthy of each,\n",
      "On each heart of toil,\n",
      "And banish'd me father\n",
      "Among the beneration\n",
      "Lord Edward prence!\n",
      "For where you have burn.\n",
      "\n",
      "CAPULET:\n",
      "what, faults hence,\n",
      "I have heard her; and,\n",
      "young prespiter'd liege,\n",
      "Unless zenelul case:\n",
      "Edward! for the noble rafe\n",
      "Suck but in extremit,\n",
      "That Prince over as her with\n",
      "were but dower them\n",
      "past my advential achie,\n",
      "Right pind to my boy.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Then, to she is my woes\n",
      "And makes me born to't;\n",
      "Which officer's mean\n",
      "His signior proport,\n",
      "Are for my answer the yieldon.\n",
      "\n",
      "LUCIO:\n",
      "If we fled country,\n",
      "Or early royal fined to\n",
      "me thequager wash'd days.\n",
      "\n",
      "HERMIONE:\n",
      "My consurate come lovi\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_str, gen_length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    input_seq = [dataset.char_to_int[c] for c in start_str[-dataset.seq_length:]]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "\n",
    "    text = start_str\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(gen_length):\n",
    "        output, hidden = model.lstm(model.embedding(input_seq), hidden)\n",
    "        output_logits = model.fc(output[:, -1, :])\n",
    "        p = torch.nn.functional.softmax(output_logits / temperature, dim=-1).detach().cpu().numpy().squeeze()\n",
    "        char_ind = np.random.choice(len(dataset.chars), p=p)\n",
    "        next_char = dataset.int_to_char[char_ind]\n",
    "        text += next_char\n",
    "\n",
    "        input_seq = torch.cat((input_seq[:, 1:], torch.tensor([[char_ind]], dtype=torch.long).to(model.device)), dim=1)\n",
    "\n",
    "    return text\n",
    "\n",
    "    \n",
    "print(generate_text(model, 'To be or not to be', gen_length=1000, temperature=1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
